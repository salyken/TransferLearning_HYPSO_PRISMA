{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bea97076",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6503a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose available CUDAs for parallell computing\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,5\"\n",
    "print(\"This notebook's PID:\", os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00909019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from skimage import exposure\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16_bn, VGG16_BN_Weights\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import gc\n",
    "\n",
    "# Import models\n",
    "import import_ipynb\n",
    "from models import HyperspectralTransferCNN, ImprovedHybrid3D2DCNN_v2, ImprovedHybrid3D2DCNN_v3, VGG16WithAttention, VGG16WithCBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee5df0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68782f6",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "782e424a",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/_shared/ARIEL/Faubai/\"\n",
    "test_folder_path = '/home/_shared/ARIEL/Faubai/TEST'\n",
    "he5_directory = \"/home/_shared/ARIEL/Faubai/datalake\"\n",
    "labels_path = '/home/salyken/PRISMA/PRISMA_data/labels_csv'\n",
    "xlsx_path = os.path.join(folder_path, '2023_02_22_Faubai_dataset_v1.xlsx')\n",
    "# save_dir_chunks = '/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/chuncked_dataset'\n",
    "save_dir_chunks = '/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/chuncked_dataset_patch_size_71'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac20424",
   "metadata": {},
   "source": [
    "### Loading Dataset from Preprocessed in the Faubai_preprocessing.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "064f9def",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChunkedDataset(Dataset):\n",
    "    def __init__(self, chunk_dir, prefix=\"train\", band_means=None, band_stds=None, augment=False, preload_all=False, clip_bands=False):\n",
    "        self.chunk_paths = sorted([\n",
    "            os.path.join(chunk_dir, f)\n",
    "            for f in os.listdir(chunk_dir)\n",
    "            if f.startswith(prefix) and f.endswith('.pt')\n",
    "        ])\n",
    "        self.clip_bands = clip_bands\n",
    "        self.index_map = []\n",
    "        if self.clip_bands:\n",
    "            # Keep only the last 47 bands (HYPSO range)\n",
    "            self.band_means = band_means[-47:].float() if band_means is not None else None\n",
    "            self.band_stds = band_stds[-47:].float() if band_stds is not None else None\n",
    "        else:\n",
    "            self.band_means = band_means.float() if band_means is not None else None\n",
    "            self.band_stds = band_stds.float() if band_stds is not None else None\n",
    "        self.augment = augment\n",
    "        self.preload_all = preload_all\n",
    "\n",
    "\n",
    "        # Sorted from longest to shortest (already known)\n",
    "        self.keep_indices = torch.tensor([\n",
    "            16, 17, 18, 19, 20, 21, 22, 23, 24, 25,\n",
    "            26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
    "            36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
    "            46, 47, 48, 49, 50, 51, 52, 53, 54, 55,\n",
    "            56, 57, 58, 59, 60, 61, 62\n",
    "        ])  # Corresponding to λ ≤ 802 nm\n",
    "\n",
    "        self.full_data = []\n",
    "        self.chunk_cache = {}\n",
    "\n",
    "        for idx, path in enumerate(tqdm(self.chunk_paths, desc=f\" Indexing {prefix} chunks\")):\n",
    "            data = torch.load(path, map_location='cpu')\n",
    "            n = len(data['y'])\n",
    "            self.index_map.extend([(idx, i) for i in range(n)])\n",
    "            if self.preload_all:\n",
    "                X = data['X'][:, self.keep_indices] if self.clip_bands else data['X']\n",
    "                self.full_data.append((X.contiguous(), data['y'].contiguous()))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        chunk_idx, sample_idx = self.index_map[idx]\n",
    "\n",
    "        if self.preload_all:\n",
    "            X, y = self.full_data[chunk_idx]\n",
    "        else:\n",
    "            if chunk_idx not in self.chunk_cache:\n",
    "                self.chunk_cache.clear()\n",
    "                data = torch.load(self.chunk_paths[chunk_idx], map_location='cpu')\n",
    "                X = data['X'][:, self.keep_indices] if self.clip_bands else data['X']\n",
    "                self.chunk_cache[chunk_idx] = (X, data['y'])\n",
    "            X, y = self.chunk_cache[chunk_idx]\n",
    "\n",
    "        sample = X[sample_idx]\n",
    "        label = y[sample_idx]\n",
    "\n",
    "        if self.band_means is not None and self.band_stds is not None:\n",
    "            sample = (sample - self.band_means[:, None, None]) / (self.band_stds[:, None, None] + 1e-6)\n",
    "\n",
    "        if self.augment:\n",
    "            sample = self.apply_augmentations(sample)\n",
    "\n",
    "        return sample.contiguous(), label\n",
    "\n",
    "    def apply_augmentations(self, x):\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            x = torch.flip(x, dims=[2])\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            x = torch.rot90(x, k=1, dims=[1, 2])\n",
    "        if torch.rand(1).item() < 0.5:\n",
    "            x = x + torch.randn_like(x) * 0.01\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2512f5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = torch.load('/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/mean_std/mean_std_71.pt')\n",
    "\n",
    "# Access tensors\n",
    "band_means = stats['band_means']\n",
    "band_stds = stats['band_stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3200a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(band_means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd395615",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = ChunkedDataset(\n",
    "    chunk_dir= save_dir_chunks,\n",
    "    prefix=\"test\",\n",
    "    band_means=band_means,\n",
    "    band_stds=band_stds,\n",
    "    augment=False,\n",
    "    preload_all=True,\n",
    "    clip_bands=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5daf0c",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104852b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, test_loader, device, class_names=None, show_confusion=True, show_timing=True):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Start timing\n",
    "    if show_timing:\n",
    "        start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Stop timing\n",
    "    if show_timing:\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        avg_time = total_time / len(test_loader.dataset)\n",
    "        print(f\"\\n Test Time: {total_time:.2f} sec\")\n",
    "        print(f\" Avg Inference Time per Sample: {avg_time:.6f} sec\")\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(classification_report(\n",
    "        all_labels, all_preds,\n",
    "        target_names=class_names if class_names else [f\"Class {i}\" for i in sorted(set(all_labels))]\n",
    "    ))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if show_confusion:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=class_names if class_names else [f\"Class {i}\" for i in sorted(set(all_labels))])\n",
    "        disp.plot(cmap='Blues', values_format='d')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "\n",
    "    # === Compute Metrics ===\n",
    "    oa = accuracy_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = np.mean(per_class_acc)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\n Overall Accuracy (OA): {oa*100:.2f}%\")\n",
    "    print(f\" Average Accuracy (AA): {aa*100:.2f}%\")\n",
    "    print(f\" Kappa Coefficient (K×100): {kappa*100:.2f}\")\n",
    "\n",
    "    # Print per-class accuracy\n",
    "    print(\"\\n Per-Class Accuracy:\")\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        class_label = class_names[i] if class_names else f\"Class {i}\"\n",
    "        print(f\"{class_label}: {acc*100:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"OA\": oa,\n",
    "        \"AA\": aa,\n",
    "        \"Kappa\": kappa,\n",
    "        \"PerClassAccuracy\": per_class_acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7677b074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG16WithAttention(input_bands=63)\n",
    "\n",
    "prisma_ckpt = \"/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/model/VGG16_w_att_71_patch/best_val_acc.pth\"\n",
    "\n",
    "# Load checkpoint\n",
    "ckpt = torch.load(prisma_ckpt, map_location=device)\n",
    "state_dict = ckpt['model_state_dict']\n",
    "\n",
    "# Remove 'module.' prefix from keys\n",
    "clean_state_dict = {k.replace('module.', ''): v for k, v in state_dict.items()}\n",
    "\n",
    "# Load into model\n",
    "model.load_state_dict(clean_state_dict)\n",
    "\n",
    "print(f\" Loaded {len(clean_state_dict)} compatible layers from PRISMA\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "model.to(device)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, num_workers=8, shuffle=False, pin_memory = True, persistent_workers=False)\n",
    "\n",
    "evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=[\"Spruce\", \"Pine\", \"Deciduous\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
