{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose available CUDAs for parallell computing\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,2,5\"\n",
    "print(\"This notebook's PID:\", os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage import exposure\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, Subset, random_split\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16_bn, VGG16_BN_Weights\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc, ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/home/_shared/ARIEL/Faubai/\"\n",
    "test_folder_path = '/home/_shared/ARIEL/Faubai/TEST'\n",
    "he5_directory = \"/home/_shared/ARIEL/Faubai/datalake\"\n",
    "labels_path = '/home/salyken/PRISMA/PRISMA_data/labels_csv'\n",
    "npy_cubes_dir = \"/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/npy_cubes\"\n",
    "\n",
    "xlsx_path = os.path.join(folder_path, '2023_02_22_Faubai_dataset_v1.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the spatial patch sizes with respect to HSI missions' GSDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prisma_image_path = '/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/npy_cubes/PRS_L1_STD_OFFL_20200421110225_20200421110229_0001.npy'\n",
    "prisma_image = np.load(prisma_image_path) \n",
    "\n",
    "\n",
    "hypso_image_path = '/home/salyken/PRISMA/HYPSO_data/cube/trondheim_2024-05-24T09-50-09Z_l1d_cube.npy' \n",
    "hypso_image = np.load(hypso_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grid_centers(image_shape, stride=32, margin=0):\n",
    "    \"\"\"\n",
    "    Generate center points in a grid across the image.\n",
    "\n",
    "    Args:\n",
    "        image_shape (tuple): Shape of the image (H, W, Bands)\n",
    "        stride (int): Distance in pixels between patch centers\n",
    "        margin (int): Padding from the edge of the image\n",
    "\n",
    "    Returns:\n",
    "        List of (row, col) tuples\n",
    "    \"\"\"\n",
    "    H, W = image_shape[:2]\n",
    "    centers = []\n",
    "\n",
    "    for row in range(margin, H - margin, stride):\n",
    "        for col in range(margin, W - margin, stride):\n",
    "            centers.append((row, col))\n",
    "    return centers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def extract_patches_by_gsd(\n",
    "    image: np.ndarray,\n",
    "    centers: list,\n",
    "    gsd: float,\n",
    "    ground_coverage: float,\n",
    "    pad_mode: str = 'reflect'\n",
    "):\n",
    "    \"\"\"\n",
    "    Extract square patches from a hyperspectral image based on ground sampling distance (GSD) and desired coverage.\n",
    "\n",
    "    Args:\n",
    "        image (np.ndarray): Hyperspectral image of shape (H, W, Bands)\n",
    "        centers (list): List of (row, col) center coordinates for patches\n",
    "        gsd (float): Ground sampling distance in meters/pixel\n",
    "        ground_coverage (float): Desired size of patch in meters (patch will be approx. this size on the ground)\n",
    "        pad_mode (str): Padding mode for boundary patches ('reflect', 'constant', etc.)\n",
    "\n",
    "    Returns:\n",
    "        List[np.ndarray]: List of extracted patches (each patch has shape (patch_size, patch_size, Bands))\n",
    "    \"\"\"\n",
    "    patches = []\n",
    "    patch_size = int(np.round(ground_coverage / gsd))\n",
    "\n",
    "    if patch_size % 2 == 0:\n",
    "        patch_size += 1  # Make patch size odd so we can center it perfectly\n",
    "\n",
    "    half_size = patch_size // 2\n",
    "    padded_image = np.pad(image, ((half_size, half_size), (half_size, half_size), (0, 0)), mode=pad_mode)\n",
    "\n",
    "    for (row, col) in centers:\n",
    "        row += half_size\n",
    "        col += half_size\n",
    "        patch = padded_image[row - half_size: row + half_size + 1,\n",
    "                             col - half_size: col + half_size + 1,\n",
    "                             :]\n",
    "        patches.append(patch)\n",
    "\n",
    "    return patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRISMA patch size: 71x71\n",
      "HYPSO patch size: 15x15\n",
      "71\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "from math import ceil\n",
    "\n",
    "prisma_gsd = 30\n",
    "hypso_gsd = 142\n",
    "coverage = 2100  # meters\n",
    "\n",
    "prisma_patch_size = ceil(coverage / prisma_gsd) \n",
    "hypso_patch_size = ceil(coverage / hypso_gsd)    \n",
    "\n",
    "if prisma_patch_size % 2 == 0:\n",
    "    prisma_patch_size += 1  \n",
    "if hypso_patch_size % 2 == 0:\n",
    "    hypso_patch_size += 1  \n",
    "\n",
    "print(f\"PRISMA patch size: {prisma_patch_size}x{prisma_patch_size}\")\n",
    "print(f\"HYPSO patch size: {hypso_patch_size}x{hypso_patch_size}\")\n",
    "\n",
    "# For PRISMA\n",
    "prisma_centers = generate_grid_centers(prisma_image.shape, prisma_patch_size)\n",
    "prisma_patches = extract_patches_by_gsd(prisma_image, prisma_centers, prisma_gsd, coverage)\n",
    "\n",
    "# For HYPSO\n",
    "hypso_centers = generate_grid_centers(hypso_image.shape, hypso_patch_size)\n",
    "hypso_patches = extract_patches_by_gsd(hypso_image, hypso_centers, hypso_gsd, coverage)\n",
    "\n",
    "\n",
    "print(prisma_patch_size)\n",
    "print(hypso_patch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened Excel file: /home/_shared/ARIEL/Faubai/2023_02_22_Faubai_dataset_v1.xlsx\n",
      "Opened Excel file: /home/_shared/ARIEL/Faubai/updated_list.xlsx\n"
     ]
    }
   ],
   "source": [
    "def file_identifier(file_path): \n",
    "\n",
    "        # file_path = os.path.join(folder_path, file)\n",
    "        \n",
    "        if file_path.endswith(\".xlsx\"):\n",
    "            df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "            print(f\"Opened Excel file: {file_path}\")\n",
    "            return df\n",
    "    \n",
    "        elif file_path.endswith(\".tif\"):\n",
    "            with rasterio.open(file_path) as src:\n",
    "                print(f\"Opened TIFF file: {file_path}, Shape:\", src.read(3).shape)\n",
    "                img = src.read(1)  # Read the first band (1-based index)\n",
    "                \n",
    "            # Display the image\n",
    "            plt.imshow(img, cmap=\"gray\")\n",
    "            plt.colorbar()\n",
    "            plt.title(\"GeoTIFF - Single Band\")\n",
    "            plt.xlabel(\"Width (X)\")\n",
    "            plt.ylabel(\"Height (Y)\")\n",
    "            plt.show()\n",
    "\n",
    "    \n",
    "        elif file_path.endswith(\".mat\"):\n",
    "            mat_data = loadmat(file_path)\n",
    "            print(f\"Opened MAT file: {file_path}, Keys:\", mat_data.keys())\n",
    "    \n",
    "        else:\n",
    "            print(f\"Skipping unknown file: {file_path}\")\n",
    "\n",
    "xlxs_ex = os.path.join(folder_path, '2023_02_22_Faubai_dataset_v1.xlsx')\n",
    "updated_list = os.path.join(folder_path, 'updated_list.xlsx') \n",
    "tif_ex = os.path.join(folder_path, 'TEST', 'PRS_L1_STD_OFFL_20200525105010_20200525105014_0001.tif')\n",
    "                       \n",
    "\n",
    "df_excel = file_identifier(xlxs_ex)\n",
    "df_updated_list = file_identifier(updated_list)\n",
    "# tif_data = file_identifier(tif_ex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 104 .he5 files.\n",
      "Found 104 .csv files.\n",
      "Found 104 data entries in xlsx file.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "he5_files = sorted([os.path.join(he5_directory, f) for f in os.listdir(he5_directory) if f.endswith(\".he5\")])\n",
    "\n",
    "print(f\"Found {len(he5_files)} .he5 files.\")\n",
    "\n",
    "csv_files = sorted([os.path.join(labels_path, f) for f in os.listdir(labels_path) if f.endswith(\".csv\")])\n",
    "\n",
    "print(f\"Found {len(csv_files)} .csv files.\")\n",
    "\n",
    "\n",
    "target_cols = [\"pine\", \"spruce\", \"deciduous\", \"water\", \"cloudsnow\"]\n",
    "\n",
    "he5_basenames = [os.path.basename(f).replace(\".he5\", \"\") for f in he5_files]\n",
    "\n",
    "xlsx_filtered = df_excel[df_excel[\"name\"].astype(str).isin(he5_basenames)]\n",
    "\n",
    "print(f\"Found {len(xlsx_filtered)} data entries in xlsx file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut Non-Informative Bands and Save HSI Cubes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_and_save_vnir_cube(name, image_dir, output_dir):\n",
    "    input_path = os.path.join(image_dir, name + \".he5\")\n",
    "    output_path = os.path.join(output_dir, name + \".npy\")\n",
    "\n",
    "    with h5py.File(input_path, 'r') as f:\n",
    "        data = f['HDFEOS']['SWATHS']['PRS_L1_HCO']['Data Fields']['VNIR_Cube'][()]\n",
    "    if data.shape[1] == 66:\n",
    "        data = np.transpose(data, (0, 2, 1))\n",
    "    elif data.shape[0] == 66:\n",
    "        data = np.transpose(data, (1, 2, 0))\n",
    "    data = data.astype(np.float32) / 65535.0\n",
    "    data = data[:, :, 3:]  # Keep only 63 bands\n",
    "    np.save(output_path, data)\n",
    "\n",
    "# Run this once\n",
    "df =  xlsx_filtered # same filtered_df used before\n",
    "image_names = df['name'].tolist()\n",
    "\n",
    "input_dir = he5_directory\n",
    "output_dir = \"/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/npy_cubes\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for name in tqdm(image_names, desc=\"Preprocessing cubes\"):\n",
    "    load_and_save_vnir_cube(name, input_dir, output_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make patch dataset for Faubai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _collect_patch_indices_for_one(args):\n",
    "    name, label_dir, half, stride, valid_labels = args\n",
    "    pattern = os.path.join(label_dir, f\"{name}_*labels.csv\")\n",
    "    matches = glob.glob(pattern)\n",
    "    if not matches:\n",
    "        return []\n",
    "\n",
    "    label_path = matches[0]\n",
    "    df = pd.read_csv(label_path, header=None)\n",
    "    label_array = df[0].apply(lambda x: list(map(int, str(x).split()))).tolist()\n",
    "    label = np.array(label_array)\n",
    "\n",
    "    h, w = label.shape\n",
    "    index_map = []\n",
    "    for i in range(half, h - half, stride):\n",
    "        for j in range(half, w - half, stride):\n",
    "            patch_labels = label[i - half:i + half + 1, j - half:j + half + 1]\n",
    "            valid = patch_labels[np.isin(patch_labels, valid_labels)]\n",
    "            if valid.size > 0:\n",
    "                index_map.append((name, i, j))\n",
    "    return index_map\n",
    "\n",
    "class HyperspectralForestDataset(Dataset):\n",
    "    _cube_cache = {}\n",
    "    _label_cache = {}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        filtered_df,\n",
    "        image_dir,\n",
    "        label_dir,\n",
    "        patch_size=71,\n",
    "        stride=15,\n",
    "        valid_labels = tuple(range(20)),  # if you don't know all of them yet,\n",
    "        majority_label=False,\n",
    "    ):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.valid_labels = valid_labels\n",
    "        self.majority_label = majority_label\n",
    "        self.half = patch_size // 2\n",
    "\n",
    "        self.image_names = filtered_df['name'].tolist()\n",
    "        self.index_map = self._collect_patch_indices()\n",
    "\n",
    "    def _load_vnir_cube(self, filepath):\n",
    "        if not os.path.exists(filepath):\n",
    "            raise FileNotFoundError(f\"VNIR cube not found: {filepath}\")\n",
    "        return np.load(filepath)\n",
    "\n",
    "    def _load_label_mask(self, name):\n",
    "        pattern = os.path.join(self.label_dir, f\"{name}_*labels.csv\")\n",
    "        matches = glob.glob(pattern)\n",
    "        if not matches:\n",
    "            raise FileNotFoundError(f\"No label file found for: {name}\")\n",
    "        label_path = matches[0]\n",
    "        df = pd.read_csv(label_path, header=None)\n",
    "        label_array = df[0].apply(lambda x: list(map(int, str(x).split()))).tolist()\n",
    "        return np.array(label_array)\n",
    "\n",
    "    def _collect_patch_indices(self):\n",
    "        print(\" Starting parallel patch collection...\")\n",
    "        args_list = [\n",
    "            (name, self.label_dir, self.half, self.stride, self.valid_labels)\n",
    "            for name in self.image_names\n",
    "        ]\n",
    "        with ProcessPoolExecutor(max_workers=32) as executor:\n",
    "            results = list(tqdm(executor.map(_collect_patch_indices_for_one, args_list), total=len(args_list)))\n",
    "        return [item for sublist in results for item in sublist]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index_map)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, i, j = self.index_map[idx]\n",
    "\n",
    "        if name not in self._cube_cache:\n",
    "            image_path = os.path.join(self.image_dir, name + \".npy\")\n",
    "            self._cube_cache[name] = self._load_vnir_cube(image_path)\n",
    "        cube = self._cube_cache[name]\n",
    "\n",
    "        if name not in self._label_cache:\n",
    "            self._label_cache[name] = self._load_label_mask(name)\n",
    "        label = self._label_cache[name]\n",
    "\n",
    "        patch = cube[i - self.half:i + self.half + 1, j - self.half:j + self.half + 1, :]\n",
    "        patch = torch.from_numpy(patch).permute(2, 0, 1)  # (Bands, H, W)\n",
    "\n",
    "        if self.majority_label:\n",
    "            patch_labels = label[i - self.half:i + self.half + 1, j - self.half:j + self.half + 1]\n",
    "            valid = patch_labels[np.isin(patch_labels, self.valid_labels)]\n",
    "            if valid.size == 0:\n",
    "                raise ValueError(f\"No valid labels in patch at {name}, {i}, {j}\")\n",
    "            label_val = int(mode(valid, axis=None).mode.item())\n",
    "        else:\n",
    "            label_val = label[i, j]\n",
    "\n",
    "        # PRISMA: 0:'other', 1:'spruce', 2:'pine', 3:'deciduous', 4:'water', 5:'cloudsnow'\n",
    "        # mapped_label = {1: 0, 2: 1, 3: 2}.get(label_val, 3)  # Map 1–3 normally, others → 3\n",
    "        mapped_label = {1: 0, 2: 1, 3: 2}[label_val] # Only using 1-3 labels, discard the rest\n",
    "\n",
    "        return patch, torch.tensor(mapped_label).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = HyperspectralForestDataset(\n",
    "    filtered_df= xlsx_filtered,\n",
    "    image_dir=npy_cubes_dir,\n",
    "    label_dir=labels_path,\n",
    "    patch_size=71,\n",
    "    stride=15,\n",
    "    majority_label=True  # enable majority labeling here\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking\n",
    "labels = [dataset[i][1].item() for i in range(0,2000)]\n",
    "print(\"Unique labels actually used in patches:\", set(labels))\n",
    "\n",
    "x, y = dataset[4000]\n",
    "print(f\"Patch shape: {x.shape}\")  # Should be (63, 71, 71)\n",
    "print(f\"Label: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Into Train/Test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lengths = [0.7, 0.15, 0.15]\n",
    "total = len(dataset)\n",
    "lengths = [int(total * l) for l in lengths]\n",
    "lengths[-1] = total - sum(lengths[:-1])  # fix rounding\n",
    "\n",
    "train_set, val_set, test_set = random_split(dataset, lengths, generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(len(val_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Dataset Into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset_in_chunks(dataset, save_dir, prefix=\"train\", batch_size=1000):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, num_workers=8, shuffle=False)\n",
    "    chunk_idx = 0\n",
    "\n",
    "    print(f\" Saving '{prefix}' batches one at a time to: {save_dir}\")\n",
    "    for batch in tqdm(loader, desc=f\"Saving {prefix} chunks\"):\n",
    "        X, y = batch\n",
    "        chunk_path = os.path.join(save_dir, f\"{prefix}_chunk_{chunk_idx}.pt\")\n",
    "        torch.save({'X': X, 'y': y}, chunk_path)\n",
    "        chunk_idx += 1\n",
    "\n",
    "    print(f\" Finished saving {chunk_idx} chunks for '{prefix}' to: {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 63, 71, 71]) tensor([2])\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=1, num_workers=0)\n",
    "for X, y in loader:\n",
    "    print(X.shape, y)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\".*can only test a child process.*\")\n",
    "\n",
    "save_chunks_dir = '/home/salyken/PRISMA/PRISMA_data/PRISMA_dataset_processed/chuncked_dataset_patch_size_71'\n",
    "\n",
    "save_dataset_in_chunks(train_set, save_chunks_dir, prefix=\"train\", batch_size=1000)\n",
    "save_dataset_in_chunks(val_set, save_chunks_dir, prefix=\"val\", batch_size=1000)\n",
    "save_dataset_in_chunks(test_set, save_chunks_dir, prefix=\"test\", batch_size=1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
