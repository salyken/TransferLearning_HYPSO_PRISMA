{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de5d7321",
   "metadata": {},
   "source": [
    "### Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5acb1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "print(\"This notebook's PID:\", os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb23748",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "import numpy as np\n",
    "import matplotlib.animation as animation\n",
    "from skimage.transform import resize\n",
    "from skimage import exposure\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from torchvision.models import vgg16_bn, VGG16_BN_Weights\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import gc\n",
    "\n",
    "import time\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    accuracy_score,\n",
    "    cohen_kappa_score\n",
    ")\n",
    "\n",
    "import import_ipynb\n",
    "from models import HyperspectralTransferCNN, ImprovedHybrid3D2DCNN_v2, VGG16WithAttention, VGG16WithCBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d220263d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Current device: {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c50796b",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49ae30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HYPSO paths\n",
    "cube_path = '/home/salyken/PRISMA/HYPSO_data/cube'\n",
    "labels_path = '/home/salyken/PRISMA/HYPSO_data/labels'\n",
    "list_path = '/home/salyken/PRISMA/HYPSO_data/list/hypso_labels.xlsx'\n",
    "split_save_path = '/home/salyken/PRISMA/HYPSO_data/list/hypso_train_val_test_split.csv'\n",
    "\n",
    "cube_files = sorted([f for f in os.listdir(cube_path) if f.endswith('.npy')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f7d9bc",
   "metadata": {},
   "source": [
    "### Creating Patch Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c4cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_patch_datasets(\n",
    "    cube_dir, label_dir, cube_list,\n",
    "    band_means=None, band_stds=None,\n",
    "    patch_size=33, stride=4,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
    "    seed=42,\n",
    "    projection_matrix=None,\n",
    "    majority_label=False  # toggleable\n",
    "):\n",
    "    class HYPSOPatchDataset(Dataset):\n",
    "        def __init__(self, cube_data, index_map, band_means, band_stds, patch_size=5, augment=False, majority_label=False):\n",
    "            self.cube_data = cube_data\n",
    "            self.index_map = index_map\n",
    "            self.band_means = band_means\n",
    "            self.band_stds = band_stds\n",
    "            self.patch_size = patch_size\n",
    "            self.half = patch_size // 2\n",
    "            self.augment = augment\n",
    "            self.majority_label = majority_label  # store flag\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.index_map)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            data = self.index_map[idx]\n",
    "            if self.majority_label:\n",
    "                cube_idx, i, j, majority = data\n",
    "                label_val = majority - 1  # already validated\n",
    "            else:\n",
    "                cube_idx, i, j = data\n",
    "                cube, label = self.cube_data[cube_idx]\n",
    "                raw_label = int(label[i, j])\n",
    "                if raw_label not in (1, 2, 3):\n",
    "                    raise ValueError(f\"Invalid label {raw_label} at index {idx}\")\n",
    "                label_val = raw_label - 1\n",
    "\n",
    "            cube, _ = self.cube_data[cube_idx]\n",
    "            patch = cube[\n",
    "                i - self.half:i + self.half + 1,\n",
    "                j - self.half:j + self.half + 1,\n",
    "                :\n",
    "            ]\n",
    "            patch = np.transpose(patch, (2, 0, 1))\n",
    "            patch = torch.tensor(patch, dtype=torch.float32)\n",
    "\n",
    "            if self.band_means is not None and self.band_stds is not None:\n",
    "                mean = torch.tensor(self.band_means[:, None, None], dtype=torch.float32)\n",
    "                std = torch.tensor(self.band_stds[:, None, None], dtype=torch.float32)\n",
    "                patch = (patch - mean) / (std + 1e-6)\n",
    "\n",
    "            if self.augment:\n",
    "                patch = self.apply_augmentations(patch)\n",
    "\n",
    "            return patch, torch.tensor(label_val).long()\n",
    "\n",
    "        def apply_augmentations(self, x):\n",
    "            if torch.rand(1) < 0.5:\n",
    "                x = torch.flip(x, dims=[1])\n",
    "            if torch.rand(1) < 0.5:\n",
    "                x = torch.flip(x, dims=[2])\n",
    "            if torch.rand(1) < 0.5:\n",
    "                x = torch.rot90(x, k=1, dims=[1, 2])\n",
    "            if torch.rand(1) < 0.5:\n",
    "                x += torch.randn_like(x) * 0.01\n",
    "            return x\n",
    "\n",
    "    # Step 1: preload cubes\n",
    "    cube_data = []\n",
    "    for fname in cube_list:\n",
    "        cube = np.load(os.path.join(cube_dir, fname))[:, :, 3:]\n",
    "        if projection_matrix is not None:\n",
    "            cube = np.tensordot(projection_matrix, cube, axes=([1], [2]))\n",
    "            cube = np.moveaxis(cube, 0, -1)\n",
    "\n",
    "        label = np.loadtxt(\n",
    "            os.path.join(label_dir, fname.replace('_l1d_cube.npy', '_labels.csv')),\n",
    "            dtype=np.uint8\n",
    "        )\n",
    "        cube_data.append((cube, label))\n",
    "\n",
    "    # Step 2: collect forest patches\n",
    "    class_map = defaultdict(list)\n",
    "    half = patch_size // 2\n",
    "\n",
    "    for cube_idx, (cube, label) in enumerate(tqdm(cube_data, desc=\"Indexing patches\")):\n",
    "        h, w = label.shape\n",
    "        for i in range(half, h - half, stride):\n",
    "            for j in range(half, w - half, stride):\n",
    "                if majority_label:\n",
    "                    patch_labels = label[i - half:i + half + 1, j - half:j + half + 1]\n",
    "                    valid = patch_labels[np.isin(patch_labels, [1, 2, 3])]\n",
    "                    if valid.size > 0:\n",
    "                        majority = mode(valid, axis=None).mode.item()\n",
    "                        if majority in (1, 2, 3):\n",
    "                            class_map[majority - 1].append((cube_idx, i, j, majority))  #  include majority\n",
    "                else:\n",
    "                    class_label = label[i, j]\n",
    "                    if class_label in (1, 2, 3):\n",
    "                        class_map[class_label - 1].append((cube_idx, i, j))\n",
    "\n",
    "    # Step 3: print class counts\n",
    "    for cls in sorted(class_map.keys()):\n",
    "        print(f\" Class {cls}: selected {len(class_map[cls])} patches\")\n",
    "\n",
    "    # Step 4–6: shuffle, split, build datasets\n",
    "    indices = [item for lst in class_map.values() for item in lst]\n",
    "    random.seed(seed)\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    n_total = len(indices)\n",
    "    n_train = int(train_ratio * n_total)\n",
    "    n_val = int(val_ratio * n_total)\n",
    "\n",
    "    train_idx = indices[:n_train]\n",
    "    val_idx = indices[n_train:n_train + n_val]\n",
    "    test_idx = indices[n_train + n_val:]\n",
    "\n",
    "    train_ds = HYPSOPatchDataset(cube_data, train_idx, band_means, band_stds, patch_size, augment=True, majority_label=majority_label)\n",
    "    val_ds = HYPSOPatchDataset(cube_data, val_idx, band_means, band_stds, patch_size, augment=False, majority_label=majority_label)\n",
    "    test_ds = HYPSOPatchDataset(cube_data, test_idx, band_means, band_stds, patch_size, augment=False, majority_label=majority_label)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13eea108",
   "metadata": {},
   "source": [
    "### With Mapping Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf6fce9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = torch.load('/home/salyken/PRISMA/HYPSO_data/HYPSO_dataset_processed/mean_std/mean_std.pt', weights_only=False)\n",
    "\n",
    "# Access tensors\n",
    "band_means = stats['band_means']\n",
    "band_stds = stats['band_stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff2a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(band_means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0250e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = create_patch_datasets(\n",
    "    cube_dir = cube_path, label_dir=labels_path, cube_list=cube_files,\n",
    "    band_means=band_means, band_stds=band_stds,\n",
    "    patch_size=71, stride=15,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
    "    seed=42,\n",
    "    majority_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3ea6ee",
   "metadata": {},
   "source": [
    "### With Projection Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b4cdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "projection_stats = torch.load('/home/salyken/PRISMA/HYPSO_data/HYPSO_dataset_processed/mean_std/projection_mean_std_47.pt', weights_only=False)\n",
    "\n",
    "# Access tensors\n",
    "projection_band_means = projection_stats['band_means']\n",
    "projection_band_stds = projection_stats['band_stds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a57ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(projection_band_means.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.load(\"/home/salyken/PRISMA/hypso_to_prisma_projection/hypso_to_prisma_projection.npy\") #shape(47,117)\n",
    "print(W.shape)\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = create_patch_datasets(\n",
    "    cube_dir = cube_path, label_dir=labels_path, cube_list=cube_files,\n",
    "    band_means=projection_band_means, band_stds=projection_band_stds,\n",
    "    patch_size=71, stride=15,\n",
    "    train_ratio=0.7, val_ratio=0.15, test_ratio=0.15,\n",
    "    seed=42,\n",
    "    projection_matrix = W,\n",
    "    majority_label=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d756d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([47, 15, 15])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "for patch in test_dataset[1]:\n",
    "    print(patch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f6f880",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81eb1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device, class_names=None, show_confusion=True, show_timing=True):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    # Start timing\n",
    "    if show_timing:\n",
    "        start_time = time.time()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Stop timing\n",
    "    if show_timing:\n",
    "        end_time = time.time()\n",
    "        total_time = end_time - start_time\n",
    "        avg_time = total_time / len(test_loader.dataset)\n",
    "        print(f\"\\n Test Time: {total_time:.2f} sec\")\n",
    "        print(f\" Avg Inference Time per Sample: {avg_time:.6f} sec\")\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"\\n Classification Report:\")\n",
    "    print(classification_report(\n",
    "        all_labels, all_preds,\n",
    "        target_names=class_names if class_names else [f\"Class {i}\" for i in sorted(set(all_labels))]\n",
    "    ))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    if show_confusion:\n",
    "        cm = confusion_matrix(all_labels, all_preds)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                                      display_labels=class_names if class_names else [f\"Class {i}\" for i in sorted(set(all_labels))])\n",
    "        disp.plot(cmap='Blues', values_format='d')\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.grid(False)\n",
    "        plt.show()\n",
    "\n",
    "    # === Compute Metrics ===\n",
    "    oa = accuracy_score(all_labels, all_preds)\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    per_class_acc = cm.diagonal() / cm.sum(axis=1)\n",
    "    aa = np.mean(per_class_acc)\n",
    "    kappa = cohen_kappa_score(all_labels, all_preds)\n",
    "\n",
    "    print(f\"\\n Overall Accuracy (OA): {oa*100:.2f}%\")\n",
    "    print(f\" Average Accuracy (AA): {aa*100:.2f}%\")\n",
    "    print(f\" Kappa Coefficient (K×100): {kappa*100:.2f}\")\n",
    "\n",
    "    # Print per-class accuracy\n",
    "    print(\"\\n Per-Class Accuracy:\")\n",
    "    for i, acc in enumerate(per_class_acc):\n",
    "        class_label = class_names[i] if class_names else f\"Class {i}\"\n",
    "        print(f\"{class_label}: {acc*100:.2f}%\")\n",
    "\n",
    "    return {\n",
    "        \"OA\": oa,\n",
    "        \"AA\": aa,\n",
    "        \"Kappa\": kappa,\n",
    "        \"PerClassAccuracy\": per_class_acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2a569c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = VGG16WithAttention(input_bands=117)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=8, pin_memory=True)\n",
    "\n",
    "ckpt = torch.load('/home/salyken/PRISMA/HYPSO_data/HYPSO_dataset_processed/models/VGG16_w_att_71_patch/without_prisma/checkpoint.pth', map_location=device)\n",
    "print(f\" Loaded checkpoint from epoch {ckpt['epoch']}\")\n",
    "model.load_state_dict(ckpt['model_state_dict'], strict=True)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Run evaluation\n",
    "evaluate_model(\n",
    "    model=model,\n",
    "    test_loader=test_loader,\n",
    "    device=device,\n",
    "    class_names=[\"Spruce\", \"Pine\", \"Deciduous\"]\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
